{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "17e44025",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in relevant modules\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import random\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from src.data import FraudDataset, prepare_train_valid_test\n",
    "from src.models import MLPClassifier\n",
    "from src.train import train\n",
    "\n",
    "# Turn off SettingWithCopyWarning\n",
    "pd.options.mode.chained_assignment = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "82280e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in the data\n",
    "df = pd.read_csv('data/creditcard.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aafaddc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get test dataset\n",
    "_, _, df_test = prepare_train_valid_test(df, valid_prop=0, test_prop=.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7d5352ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(\n",
       "  (network): Sequential(\n",
       "    (0): Dropout(p=0.5, inplace=False)\n",
       "    (1): Linear(in_features=30, out_features=30, bias=True)\n",
       "    (2): BatchNorm1d(30, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): ReLU()\n",
       "    (4): Dropout(p=0.5, inplace=False)\n",
       "    (5): Linear(in_features=30, out_features=30, bias=True)\n",
       "    (6): BatchNorm1d(30, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (7): ReLU()\n",
       "    (8): Dropout(p=0.5, inplace=False)\n",
       "    (9): Linear(in_features=30, out_features=30, bias=True)\n",
       "    (10): BatchNorm1d(30, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (11): ReLU()\n",
       "    (12): Dropout(p=0.5, inplace=False)\n",
       "    (13): Linear(in_features=30, out_features=2, bias=True)\n",
       "    (14): ReLU()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load in models\n",
    "filename = 'logistic_regression.pickle'\n",
    "lr_model =  pickle.load(open('model_files/' + filename, \"rb\"))\n",
    "\n",
    "mlp_model = MLPClassifier(n_input=30, layers=[30, 30, 30, 2], dropout=.5)\n",
    "mlp_model.load_state_dict(torch.load('model_files/mlp.th'))\n",
    "mlp_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bae19788",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate predictions for both models on the test set\n",
    "lr_preds = lr_model.predict(df_test[df_test.columns[:-1]])\n",
    "\n",
    "test_data = DataLoader(FraudDataset(df_test), batch_size=1024, shuffle=False)\n",
    "mlp_preds = mlp_model(torch.tensor(df_test.iloc[:, :-1].values).float())\n",
    "class_preds = (mlp_preds / torch.sum(mlp_preds, dim=1).reshape(-1, 1))\n",
    "class_1_probs = mlp_preds[:, 1].detach().numpy()\n",
    "mlp_preds = [0 if pred < 1 else 1 for pred in class_1_probs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "99db4417",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find observations for where the two models agree. If that is the case,\n",
    "# then predict 1. Else predict 0.\n",
    "mlp_indices = []\n",
    "for idx in range(len(mlp_preds)):\n",
    "    if mlp_preds[idx] == 1:\n",
    "        mlp_indices.append(idx)\n",
    "        \n",
    "lr_indices = []\n",
    "for idx in range(len(lr_preds)):\n",
    "    if lr_preds[idx] == 1:\n",
    "        lr_indices.append(idx)\n",
    "        \n",
    "strong_positives = set(mlp_indices).intersection(set(lr_indices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "fb196ba5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 99.96%\n",
      "precision: 94.05%\n",
      "recall: 73.15%\n"
     ]
    }
   ],
   "source": [
    "# Evaluate performance on the test set\n",
    "ensemble_preds = np.array([0 if idx not in strong_positives else 1 for _ in range(len(mlp_preds))])\n",
    "fraud_indices = np.array(list(df_test.reset_index()[df_test.reset_index()['Class'] == 1].index))\n",
    "not_fraud_indices = np.array(list(df_test.reset_index()[df_test.reset_index()['Class'] == 0].index))\n",
    "tp = len(strong_positives.intersection(set(fraud_indices)))\n",
    "fn = len(fraud_indices) - tp\n",
    "fp = len(strong_positives) - tp\n",
    "tn = len(not_fraud_indices) - fn\n",
    "print(f'accuracy: {np.round(100 * (tp+tn) / (tp+fp+tn+fn), 2)}%')\n",
    "print(f'precision: {np.round(100 * tp / (tp+fp), 2)}%')\n",
    "print(f'recall: {np.round(100 * tp / (tp+fn), 2)}%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
